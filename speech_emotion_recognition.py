# -*- coding: utf-8 -*-
"""Speech_Emotion_Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N-DUJX15TGpMlu4v2vC68VGxI22PcKbO

<h2><b> Connecting to Kaggle </b></h2>
"""

# from google.colab import drive
# drive.mount('/content/drive')

# # Importing the 'files' module from Google Colab which allows file operations in Colab
# from google.colab import files
# files.upload()

# !mkdir -p ~/.kaggle
# !cp kaggle.json ~/.kaggle/
# !chmod 600 /root/.kaggle/kaggle.json

"""<h2><b> Downloading the Dataset </b></h2>"""

!kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess

"""<h2><b> Unzipping the Dataset </b></h2>"""

import zipfile
zip_ref = zipfile.ZipFile('/content/toronto-emotional-speech-set-tess.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""<h2><b> Importing the Modules </b></h2>"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import librosa
import librosa.display
from IPython.display import Audio

import torchaudio
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import Wav2Vec2Model, Wav2Vec2Processor, Trainer, TrainingArguments, Wav2Vec2ForSequenceClassification

import warnings
warnings.filterwarnings('ignore')

"""<h2><b> Loading the Audio Files </b></h2>"""

# An empty list to store file paths
paths = []

# An empty list to store labels corresponding to the file paths
labels = []

import os
path = r'/content/TESS Toronto emotional speech set data'
base_dir = path

# Loop through the directory tree starting from 'base_dir'

for dirname, _, filenames in os.walk(base_dir):
    for filename in filenames:

        # Append the path and filename to the 'paths' list
        paths.append(os.path.join(dirname, filename))

        # Extract the label from the filename by splitting it by the '_' character
        # The label is assumed to be the last part after the underscore
        label = filename.split('_')[-1]

        # Further split the label by the '.' to remove the file extension and get the raw label
        label = label.split('.')[0]

         # Convert the label to lowercase for consistency and append it to the 'labels' list
        labels.append(label.lower())

len(paths)

# Create an empty DataFrame
df = pd.DataFrame()

# Add a 'speech' column to the DataFrame containing file paths
df['speech'] = paths

# Add a 'label' column to the DataFrame containing the corresponding labels
df['label'] = labels

sns.countplot(data=df, x='label')

paths[:25]

labels[:25]

df['speech']

df['label']

"""<h2><b> Exploratory Data Analysis </b></h2>"""

# Function to plot the waveform of an audio signal
def waveplot(data, sr, emotion):
    plt.figure(figsize=(10,4)) # Create a new figure with a specified size
    plt.title(emotion, size=20) # Set the title of the plot to the specified emotion
    librosa.display.waveshow(data, sr=sr) # Display the waveform of the audio data
    plt.show()

# Function to plot the spectrogram of an audio signal
def spectogram(data, sr, emotion):
    x = librosa.stft(data) # Compute the Short-Time Fourier Transform
    xdb = librosa.amplitude_to_db(abs(x)) # Convert the amplitude to decibels (dB)
    plt.figure(figsize=(11,4))   # Create a new figure with a specified size
    plt.title(emotion, size=20) # Set the title of the plot
    # Display the spectrogram using librosa's specshow function
    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')
    plt.colorbar()

# Loop through each emotion in the emotions list
emotions = ['fear', 'ps', 'sad', 'angry', 'disgust', 'happy', 'neutral']

# Loop through each emotion in the emotions list
for emotion in emotions:
    # Get the first file path corresponding to the current emotion
    path = np.array(df['speech'][df['label']==emotion])[0]
    # Load the audio file from the specified path using librosa
    data, sampling_rate = librosa.load(path)
    # Call the waveplot function to visualize the waveform
    waveplot(data, sampling_rate, emotion)
    # Call the spectogram function to visualize the spectrogram
    spectogram(data, sampling_rate, emotion)

"""<h2><b> MFCC Feature Extraction </b></h2>"""

# Function to extract MFCC features
def extract_mfcc(filename):
    # Load the audio file with librosa
    # 'duration' specifies the length of the audio clip to load (in seconds)
    # 'offset' specifies the start time to load the audio
    y, sr = librosa.load(filename, duration=3, offset=0.5)

    # Extract MFCC features from the audio data
    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=60).T, axis=0)

    return mfcc

# Apply the extract_mfcc function to each audio file path in the 'speech' column of the DataFrame
X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))

X_mfcc

# Convert the Series of MFCC features (X_mfcc) into a list
X = [x for x in X_mfcc]

# Convert the list of MFCC features into a NumPy array
X = np.array(X)

X

# Expand the dimensions of the NumPy array X to add an additional axis at the end
X = np.expand_dims(X, -1)
X

from sklearn.preprocessing import OneHotEncoder

# Initialize the OneHotEncoder
enc = OneHotEncoder()

# Apply OneHotEncoder to the 'label' column of the DataFrame
# The fit_transform method fits the encoder to the data and then transforms it into a one-hot encoded format
y = enc.fit_transform(df[['label']])
y

# Convert the sparse matrix of one-hot encoded labels to a dense NumPy array
y = y.toarray()
y

"""<h2><b> Creating Train and Test Dataset </b></h2>"""

from sklearn.model_selection import train_test_split

# Split the dataset into training and testing sets
# X contains the features (MFCCs), y contains the one-hot encoded labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print the shapes of the resulting datasets
print(f"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}")
print(f"Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}")

"""<h2><b>Neural Architecture Search</b></h2>

<h2><b>1. LSTM Model </b></h2>
"""

!pip install keras-tuner

import tensorflow as tf
from keras import layers, models
from keras_tuner import HyperModel, RandomSearch
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from kerastuner import HyperModel
from kerastuner.tuners import RandomSearch
from tensorflow.keras.optimizers import Adam

# Define a model-building function with LSTM layers only
class AudioModel(HyperModel):
    def build(self, hp):
        model = Sequential()
        model.add(layers.Input(shape=X_train.shape[1:]))  # Assuming X_train shape is (60, 1)

        # Add LSTM layers with tunable parameters
        for i in range(hp.Int('num_lstm_layers', 1, 3)):  # Tuning number of LSTM layers
            model.add(layers.LSTM(
                units=hp.Int(f'lstm_units_{i}', 32, 128, step=32),
                return_sequences=(i < hp.Int('num_lstm_layers', 1, 3) - 1)  # Only last layer should not return sequences
            ))
            model.add(layers.Dropout(0.2))  # Adding dropout for regularization

        model.add(layers.Flatten())  # Flatten before dense layers

        # Dense layers with tunable units
        for j in range(hp.Int('num_dense_layers', 1, 3)):  # Tuning number of dense layers
            model.add(layers.Dense(
                units=hp.Int(f'units_{j}', 32, 128, step=16),
                activation='relu'
            ))
            model.add(layers.Dropout(0.2))  # Adding dropout for regularization

        # Output layer with softmax activation
        model.add(layers.Dense(y_train.shape[1], activation='softmax'))

        # Compile model with a hyperparameter-tuned optimizer
        model.compile(optimizer=hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']),
                      loss='categorical_crossentropy',
                      metrics=['accuracy'])
        return model

# Set up the Keras Tuner
tuner = RandomSearch(
    AudioModel(),
    objective='val_accuracy',
    max_trials=10,
    executions_per_trial=3,
    directory='audio_tuner',
    project_name='audio_recognition'
)

# Perform the search
tuner.search(X_train, y_train, epochs=10, validation_split=0.2)

# Get the best model
best_model = tuner.get_best_models(num_models=1)[0]

print("\nBest Model Architecture:")
print("Optimizer details:", best_model.optimizer)
best_model.summary()

loss, accuracy = best_model.evaluate(X_test, y_test)
print(f"Test accuracy: {accuracy * 100:.6f}")

"""<h2><b> Model <b></h2>

<h3><b> 1. Transformer Model </b></h3>

<h4><b>Create Custom Dataset Class</b></h4>
"""

df_tf = df

label_map = {label: idx for idx, label in enumerate(df['label'].unique())}
inverse_label_map = {idx: label for label, idx in label_map.items()}
df_tf['label'] = df['label'].map(label_map)
df_tf.head(2)

len(df_tf)

class SpeechEmotionDataset(Dataset):
    def __init__(self, df_tf, processor, max_length=32000):
        self.df_tf = df_tf
        self.processor = processor
        self.max_length = max_length

    def __len__(self):
        return len(self.df_tf)

    def __getitem__(self, idx):
        audio_path = self.df_tf.iloc[idx]['speech']
        label = self.df_tf.iloc[idx]['label']

        # load the audio file
        speech, sr = librosa.load(audio_path, sr=16000)

        # pad or turncate the speech to the required length
        if len(speech) > self.max_length:
            speech = speech[:self.max_length]
        else:
            speech = np.pad(speech, (0, self.max_length - len(speech)), 'constant')

        # preprocess the audio file
        inputs = self.processor(speech, sampling_rate=16000, return_tensors='pt', padding=True, truncate=True, max_length=self.max_length)

        input_values = inputs.input_values.squeeze()
        return {'input_values': input_values, 'labels': torch.tensor(label, dtype=torch.long)}

from sklearn.model_selection import train_test_split
train_tf, test_tf = train_test_split(df_tf, test_size=0.2, random_state=42)

print("train_tf.shape", train_tf.shape)
print("test_tf.shape", test_tf.shape)

# initiate the processor and model
processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base')
tf_model = Wav2Vec2ForSequenceClassification.from_pretrained('facebook/wav2vec2-base', num_labels=7)

# load the Dataset
train_dataset = SpeechEmotionDataset(train_tf, processor)
test_dataset = SpeechEmotionDataset(test_tf, processor)

train_dataset[0]['input_values'].size()

# create dataloaders
train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)

"""<h2><b>Set Training Parameter</b></h2>"""

training_args = TrainingArguments(
    output_dir='content/results',
    evaluation_strategy='epoch',
    save_strategy='epoch',
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    report_to=[]
)

# create functions for computing matics
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids # origin labels
    preds = np.argmax(pred.predictions, axis=1) # model predicted labels
    accuracy = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

# initialize the trainer
trainer = Trainer(
    model=tf_model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics
)

trainer.train()

result = trainer.evaluate()
print(result)

result

import random
idx = random.randrange(0, len(test_dataset))

# Retrieve and print the original label
original_label = test_dataset[idx]['labels']
print('Original Label:', inverse_label_map[int(original_label)])

# Retrieve input values, unsqueeze, and move to GPU
input_values = test_dataset[idx]['input_values'].unsqueeze(0).cuda()

# Perform inference
with torch.no_grad():
    outputs = tf_model(input_values)
    logits = outputs.logits

# Get the predicted class
predicted_class = logits.argmax(dim=-1).item()
print('Predicted Label:', inverse_label_map[predicted_class])

processor.save_pretrained('./wav2vec2_model')
tf_model.save_pretrained('./wav2vec2_model')

# from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor

# # Path to save the model
# model_save_path = "./wave2vec_model"


# # Save the model and feature extractor
# tf_model.save_pretrained(model_save_path)  # Saves model weights and config.json
# feature_extractor.save_pretrained(model_save_path)  # Saves preprocessor_config.json

# print(f"Model and feature extractor saved to {model_save_path}")

# import shutil

# # Zip the folder
# shutil.make_archive('wave2vec_model', 'zip', './wave2vec_model')

# print("Model folder zipped successfully.")
# from google.colab import files

# # Download the zip file
# files.download('wave2vec_model.zip')

"""<h3><b> 2. LSTM (256) <b></h3>"""

import tensorflow as tf
from keras.models import Sequential
from tensorflow.keras.models import Model
from keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.layers import GRU, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import precision_score, recall_score, mean_squared_error
from tensorflow.keras.layers import Input, LayerNormalization, MultiHeadAttention, Embedding, Flatten

# Define the teacher model using Sequential API
lstm_256_teacher_model = Sequential([

    # First LSTM layer with 256 units, return_sequences=False since it's the last LSTM layer
    # Input shape is (60, 1) where 60 is the number of time steps and 1 is the feature per time step
    LSTM(256, return_sequences=False, input_shape=(60, 1)),

    Dropout(0.2), # Prevent Overfitting

    # Dense layer with 128 units and ReLU activation
    Dense(128, activation='relu'),

    Dropout(0.2), # Prevent Overfitting

    # Dense layer with 64 units and ReLU activation
    Dense(64, activation='relu'),
    Dropout(0.2), # Prevent Overfitting

     # Output layer with 7 units (corresponding to the number of classes), using softmax activation
    Dense(7, activation='softmax') # Softmax is used for multiclass classification
])

# Compile the teacher model
lstm_256_teacher_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Print a summary of the teacher model
lstm_256_teacher_model.summary()

from tensorflow.keras.utils import plot_model

# Print the architecture of the model
lstm_256_teacher_model.summary()

# Optionally save a visual representation of the architecture
plot_model(
    lstm_256_teacher_model,
    to_file="teacher_model_architecture.png",
    show_shapes=True,
    show_layer_names=True
)

# Define the early stopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',     # Track validation loss
    patience=5,             # Stop after 5 epochs without improvement
    restore_best_weights=True  # Restore the best weights after stopping
)

lstm_256_teacher_history = lstm_256_teacher_model.fit(
    X_train,  # The input training data (MFCC features)
    y_train,  # The one-hot encoded labels for the training data
    validation_split=0.2, # Use 20% of the training data as validation set
    epochs=50, # Train the model for 50 epochs
    batch_size=64, # Use mini-batches of size 64 for each training step
    callbacks=[early_stopping]     # Include early stopping callback
)

# Check how many epochs were run
print(f"Model trained for {len(lstm_256_teacher_history.epoch)} epochs.")

# lstm_256_teacher_model.save('/content/drive/MyDrive/Sentiment_Analysis/lstm_256_teacher_lstm.hdf5')

"""<h3><b>3. LSTM Model (128)</b></h3>"""

lstm_128_teacher_model = Sequential([
    LSTM(128, return_sequences=False, input_shape=(60, 1)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(7, activation='softmax')
])

lstm_128_teacher_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_128_teacher_model.summary()

# Define the early stopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',     # Track validation loss
    patience=5,             # Stop after 5 epochs without improvement
    restore_best_weights=True  # Restore the best weights after stopping
)

lstm_128_teacher_history = lstm_128_teacher_model.fit(
    X_train, # The input training data (MFCC features)
    y_train, # The one-hot encoded labels for the training data
    validation_split=0.2, # Use 20% of the training data as validation set
    epochs=50, # Train the model for 50 epochs
    batch_size=64, # Use mini-batches of size 64 for each training step
    callbacks=[early_stopping] # Include early stopping callback
)

# Check how many epochs were run
print(f"Model trained for {len(lstm_128_teacher_history.epoch)} epochs.")

"""<h3><b> 4. GRU Model (128) </b><h3>"""

# Build the GRU model for multiclass classification
gru_model = Sequential()

# Add a GRU layer
gru_model.add(GRU(units=128, input_shape=(X_train.shape[1], X_train.shape[2])))

# Optional Dropout layer
gru_model.add(Dropout(0.2))

# Output layer for multiclass classification (7 classes)
gru_model.add(Dense(7, activation='softmax'))

# Compile the model (with categorical crossentropy for multiclass classification)
gru_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
gru_model.summary()

# Early stopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',     # Monitors validation loss
    patience=5,             # Stops after 5 epochs without improvement
    restore_best_weights=True  # Restores the best model weights after stopping
)

# Train the model with early stopping
gru_history = gru_model.fit(
    X_train,  # The input training data (shape: (2240, 60, 1))
    y_train,  # The one-hot encoded labels for the training data (shape: (2240, 7))
    validation_split=0.2,  # Use 20% of the training data as validation set
    epochs=50,  # Train the model for 50 epochs
    batch_size=64,  # Use mini-batches of size 64 for each training step
    callbacks=[early_stopping]  # Include early stopping callback
)

# Check how many epochs were run
print(f"Model trained for {len(gru_history.epoch)} epochs.")

# Define the Transformer block
def transformer_block(x, head_size, num_heads, ff_dim, dropout=0):
    # Normalization and Attention
    x_norm = LayerNormalization(epsilon=1e-6)(x)
    x_attn = MultiHeadAttention(
        key_dim=head_size, num_heads=num_heads, dropout=dropout
    )(x_norm, x_norm)
    x = Dropout(dropout)(x_attn)
    x = x + x_norm  # Residual connection

    # Feed Forward Part
    x_ff = Dense(ff_dim, activation="relu")(x)
    x_ff = Dropout(dropout)(x_ff)
    x_ff = Dense(x.shape[-1])(x_ff)
    x = x + x_ff  # Residual connection
    return x

# Build the Transformer model
def build_transformer(input_shape, num_classes, head_size, num_heads, ff_dim, num_transformer_blocks, dropout=0):
    inputs = Input(shape=input_shape)
    x = inputs
    for _ in range(num_transformer_blocks):
        x = transformer_block(x, head_size, num_heads, ff_dim, dropout)

    x = LayerNormalization(epsilon=1e-6)(x)
    x = Flatten()(x)  # Flatten before the output layer
    x = Dense(num_classes, activation='softmax')(x)  # Output layer for multiclass classification
    return Model(inputs, x)

# Parameters for the Transformer model
input_shape = (60, 1)  # (time steps, features)
num_classes = 7  # Number of classes
head_size = 64  # Size of the attention heads
num_heads = 4  # Number of attention heads
ff_dim = 128  # Dimensionality of the feed forward layer
num_transformer_blocks = 2  # Number of transformer blocks
dropout = 0.2  # Dropout rate

# Build the model
transformer_model = build_transformer(input_shape, num_classes, head_size, num_heads, ff_dim, num_transformer_blocks, dropout)

# Compile the model
transformer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

transformer_model.summary()

# Early stopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',     # Monitors validation loss
    patience=5,             # Stops after 5 epochs without improvement
    restore_best_weights=True  # Restores the best model weights after stopping
)

# Train the model with early stopping
transformer_history = transformer_model.fit(
    X_train,  # The input training data (shape: (2240, 60, 1))
    y_train,  # The one-hot encoded labels for the training data (shape: (2240, 7))
    validation_split=0.2,  # Use 20% of the training data as validation set
    epochs=50,  # Train the model for 50 epochs
    batch_size=64,  # Use mini-batches of size 64 for each training step
    callbacks=[early_stopping]  # Include early stopping callback
)

"""<h2><b> Comparing Teacher and Hit & Trial LSTM Model </b></h2>"""

models = [lstm_256_teacher_model, lstm_128_teacher_model, gru_model, transformer_model]
# models = [lstm_256_teacher_model, lstm_128_teacher_model, gru_model]

for model in models:
    loss, accuracy = model.evaluate(X_test, y_test)

    # Make predictions on the test set
    y_pred_prob = model.predict(X_test)
    y_pred = (y_pred_prob > 0.5).astype("int32")  # Convert probabilities to binary class (0 or 1)

    # Calculate precision, recall
    precision = precision_score(y_test, y_pred, average='macro')
    recall = recall_score(y_test, y_pred, average='macro')

    # Calculate RMSE
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_prob))

    # Print accuracy, loss, precision, recall, and RMSE
    print(f"Model: {model}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Loss: {loss:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"RMSE: {rmse:.4f}")

"""<h2><b> Model Compression by Knowledge Distillation</b></h2>"""

from keras.losses import KLDivergence, CategoricalCrossentropy
from keras.optimizers import Adam

categorical_loss = CategoricalCrossentropy(from_logits=False)
kl_div_loss = KLDivergence()

"""<h2><b> Creating Student LSTM (256) Model</b></h2>"""

lstm_256_student_model = Sequential([
    LSTM(256, return_sequences=False, input_shape=(60, 1)),
    Dropout(0.2),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(7, activation='softmax')
])

lstm_256_student_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_256_student_model.summary()

def lstm_256_distillation_loss(y_true, y_pred, teacher_pred, alpha=0.1, temperature=3):

    # Compute the categorical cross-entropy loss between true labels and student predictions
    lstm_256_loss_ce = categorical_loss(y_true, y_pred)

     # Apply temperature scaling to the teacher's predictions and compute soft labels
    lstm_256_teacher_soft = tf.nn.softmax(teacher_pred / temperature)

    # Apply temperature scaling to the student's predictions to create soft labels
    lstm_256_student_soft = tf.nn.softmax(y_pred / temperature)

    # Compute KL divergence between the soft labels of teacher and student
    lstm_256_loss = kl_div_loss(lstm_256_teacher_soft, lstm_256_student_soft)

    # Combine both loss components: KL divergence and cross-entropy
    return alpha * lstm_256_loss + (1 - alpha) * lstm_256_loss_ce

def lstm_256_train_step(X_batch, y_batch):
    with tf.GradientTape() as tape:
        # Get predictions from the teacher model
        lstm_256_teacher_pred = lstm_256_teacher_model(X_batch, training=False)

        # Get predictions from the student model
        lstm_256_student_pred = lstm_256_student_model(X_batch, training=True)

        # Calculate the distillation loss
        lstm_256_loss = lstm_256_distillation_loss(y_batch, lstm_256_student_pred, lstm_256_teacher_pred)

    # Compute gradients and update weights
    lstm_256_gradients = tape.gradient(lstm_256_loss, lstm_256_student_model.trainable_variables)
    optimizer.apply_gradients(zip(lstm_256_gradients, lstm_256_student_model.trainable_variables))

    return loss

# Placeholder for validation loss calculation
def calculate_validation_loss(X_val, y_val):
    val_loss = 0
    num_val_batches = math.ceil(len(X_val) / batch_size)
    for batch_idx in range(num_val_batches):
        X_batch_val = X_val[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        y_batch_val = y_val[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        teacher_pred = lstm_256_teacher_model(X_batch_val, training=False)
        student_pred = lstm_256_student_model(X_batch_val, training=False)
        val_loss += lstm_256_distillation_loss(y_batch_val, student_pred, teacher_pred)
    return val_loss / num_val_batches

optimizer = Adam()

import math

# Set parameters for training
batch_size = 64
num_batches = math.ceil(len(X_train) / batch_size)
epochs = 25
patience = 5
best_val_loss = np.inf
patience_counter = 0

# Early stopping and training loop
for epoch in range(epochs):
    print(f"Epoch {epoch + 1}/{epochs}")

    # Training step
    for batch_idx in range(num_batches):
        X_batch = X_train[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        y_batch = y_train[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        train_loss = lstm_256_train_step(X_batch, y_batch)

    # Validation step
    val_loss = calculate_validation_loss(X_test, y_test)
    print(f"Val Loss: {val_loss}")

    # Early stopping logic
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        # Save the best model
        # lstm_256_student_model.save('best_model.hdf5')
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print("Early stopping triggered. Stopping training.")
            break

"""<h2><b> Creating Student LSTM (128) Model</b></h2>"""

lstm_128_student_model = Sequential([
    LSTM(128, return_sequences=False, input_shape=(60, 1)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(7, activation='softmax')
])

lstm_128_student_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_128_student_model.summary()

def lstm_128_distillation_loss(y_true, y_pred, teacher_pred, alpha=0.1, temperature=3):

    # Compute the categorical cross-entropy loss between true labels and student predictions
    lstm_128_loss_ce = categorical_loss(y_true, y_pred)

     # Apply temperature scaling to the teacher's predictions and compute soft labels
    lstm_128_teacher_soft = tf.nn.softmax(teacher_pred / temperature)

    # Apply temperature scaling to the student's predictions to create soft labels
    lstm_128_student_soft = tf.nn.softmax(y_pred / temperature)

    # Compute KL divergence between the soft labels of teacher and student
    lstm_128_loss = kl_div_loss(lstm_128_teacher_soft, lstm_128_student_soft)

    # Combine both loss components: KL divergence and cross-entropy
    return alpha * lstm_128_loss + (1 - alpha) * lstm_128_loss_ce

def lstm_128_train_step(X_batch, y_batch):
    with tf.GradientTape() as tape:
        # Get predictions from the teacher model
        lstm_128_teacher_pred = lstm_128_teacher_model(X_batch, training=False)

        # Get predictions from the student model
        lstm_128_student_pred = lstm_128_student_model(X_batch, training=True)

        # Calculate the distillation loss
        lstm_128_loss = lstm_128_distillation_loss(y_batch, lstm_128_student_pred, lstm_128_teacher_pred)

    # Compute gradients and update weights
    lstm_128_gradients = tape.gradient(lstm_128_loss, lstm_128_student_model.trainable_variables)
    optimizer.apply_gradients(zip(lstm_128_gradients, lstm_128_student_model.trainable_variables))

    return loss

# Validation loss calculation function
def calculate_validation_loss(X_val, y_val):
    val_loss = 0
    num_val_batches = math.ceil(len(X_val) / batch_size)
    for batch_idx in range(num_val_batches):
        X_batch_val = X_val[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        y_batch_val = y_val[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        teacher_pred = lstm_128_teacher_model(X_batch_val, training=False)
        student_pred = lstm_128_student_model(X_batch_val, training=False)
        val_loss += lstm_128_distillation_loss(y_batch_val, student_pred, teacher_pred)
    return val_loss / num_val_batches

optimizer = Adam()

import math

# Set parameters for training
batch_size = 64
num_batches = math.ceil(len(X_train) / batch_size)
epochs = 25
patience = 5
best_val_loss = np.inf
patience_counter = 0

# Early stopping and training loop
for epoch in range(epochs):
    print(f"Epoch {epoch + 1}/{epochs}")

    # Training step
    for batch_idx in range(num_batches):
        X_batch = X_train[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        y_batch = y_train[batch_idx * batch_size: (batch_idx + 1) * batch_size]
        train_loss = lstm_128_train_step(X_batch, y_batch)

    # Validation step
    val_loss = calculate_validation_loss(X_test, y_test)
    print(f"val loss: {val_loss}")

    # Early stopping logic
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        # Save the best model
        # lstm_128_student_model.save('best_model.hdf5')
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print("Early stopping triggered. Stopping training.")
            break

# Final model save
# lstm_128_student_model.save('/content/drive/MyDrive/Sentiment_Analysis/compressed_student_lstm.hdf5')

import numpy as np
import tensorflow as tf
from tensorflow.keras import Sequential, layers
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import losses, optimizers
from sklearn.model_selection import train_test_split

def create_student_gru_model(input_shape, num_classes):
    gru_model_student = Sequential()
    gru_model_student.add(layers.GRU(units=64, input_shape=input_shape))  # Smaller GRU layer
    gru_model_student.add(layers.Dropout(0.2))  # Optional Dropout layer
    gru_model_student.add(layers.Dense(num_classes, activation='softmax'))  # Output layer
    return gru_model_student

# Knowledge distillation loss function
def gru_model_loss(gru_model_teacher_y_true, gru_model_student_y_pred, gru_model_teacher_pred, temperature=3, alpha=0.5):
    # Soft targets loss (KL divergence)
    gru_model_teacher_soft_targets = tf.nn.softmax(gru_model_teacher_pred / temperature)
    gru_model_student_soft = tf.nn.softmax(gru_model_student_y_pred / temperature)
    gru_model_student_soft_loss = losses.KLDivergence()(gru_model_teacher_soft_targets, gru_model_student_soft)

    # Hard targets loss (standard cross-entropy with true labels)
    gru_model_student_hard_loss = losses.CategoricalCrossentropy()(gru_model_teacher_y_true, gru_model_student_y_pred)

    # Combined loss: weighting between soft and hard targets
    return alpha * gru_model_student_soft_loss + (1 - alpha) * gru_model_student_hard_loss

# Function to train the student model with knowledge distillation and early stopping
def train_student_with_distillation(gru_model_student, gru_model_teacher, X_train, y_train, X_test, y_test, epochs=50, batch_size=64, temperature=3, alpha=0.5):
    optimizer = optimizers.Adam()

    # Split training data for validation
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    # Early stopping parameters
    best_val_loss = float('inf')
    patience = 5
    patience_counter = 0

    for epoch in range(epochs):
        print(f"Epoch {epoch + 1}/{epochs}")

        # Training loop
        for i in range(0, len(X_train), batch_size):
            X_batch = X_train[i:i + batch_size]
            y_batch = y_train[i:i + batch_size]

            with tf.GradientTape() as tape:
                # Teacher and student predictions
                teacher_pred = gru_model_teacher(X_batch, training=False)
                student_pred = gru_model_student(X_batch, training=True)

                # Calculate distillation loss
                loss = gru_model_loss(y_batch, student_pred, teacher_pred, temperature, alpha)

            # Backpropagation
            grads = tape.gradient(loss, gru_model_student.trainable_variables)
            optimizer.apply_gradients(zip(grads, gru_model_student.trainable_variables))

        # Validation after each epoch
        val_loss, val_acc = gru_model_student.evaluate(X_val, y_val, verbose=0)
        print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}")

        # Early stopping check
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            # Save the best model
            # gru_model_student.save('best_gru_model_student.hdf5')
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print("Early stopping triggered. Stopping training.")
                break

    # Evaluate final model on the test set
    test_loss, test_acc = gru_model_student.evaluate(X_test, y_test, verbose=0)
    print(f"val Loss: {test_loss:.4f}, val Accuracy: {test_acc:.4f}")

# Define input shape and number of classes
input_shape = (X_train.shape[1], X_train.shape[2])  # Same as the parent model
num_classes = 7  # Number of classes for SER

# Create the student GRU model
gru_model_student = create_student_gru_model(input_shape, num_classes)

# Compile the student model (this is optional; you can compile it after training)
gru_model_student.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
gru_model_student.summary()

# Train the student model using knowledge distillation and early stopping
train_student_with_distillation(
    gru_model_student,
    gru_model,
    X_train,
    y_train,
    X_test,
    y_test,
    epochs=25,
    batch_size=64
)

"""<h2><b> Comparing Teacher and Student LSTM (256) Model </b></h2>"""

tm_256_test_loss, tm_256_test_accuracy = lstm_256_teacher_model.evaluate(X_test, y_test)
print(f"Teacher Model Test Accuracy: {tm_256_test_accuracy * 100}")

sm_256_test_loss, sm_256_test_accuracy = lstm_256_student_model.evaluate(X_test, y_test, batch_size=64, verbose=0)
print(f"Student Model Test Accuracy: {sm_256_test_accuracy * 100}")

lstm_256_accuracy_diff = tm_256_test_accuracy - sm_256_test_accuracy
print(f"Accuracy Difference (Teacher - Student): {lstm_256_accuracy_diff * 100}%")

"""<h2><b> Comparing Teacher and Student LSTM (128) Model </b></h2>"""

tm_128_test_loss, tm_128_test_accuracy = lstm_128_teacher_model.evaluate(X_test, y_test)
print(f"Teacher Model Test Accuracy: {tm_128_test_accuracy * 100}")

sm_128_test_loss, sm_128_test_accuracy = lstm_128_student_model.evaluate(X_test, y_test, batch_size=64, verbose=0)
print(f"Student Model Test Accuracy: {sm_128_test_accuracy * 100}")

lstm_128_accuracy_diff = tm_128_test_accuracy - sm_128_test_accuracy
print(f"Accuracy Difference (Teacher - Student): {lstm_128_accuracy_diff * 100}%")

tm_gru_test_loss, tm_gru_test_accuracy = gru_model.evaluate(X_test, y_test)
print(f"Teacher Model Test Accuracy: {tm_gru_test_accuracy * 100}")

sm_gru_test_loss, sm_gru_test_accuracy = gru_model_student.evaluate(X_test, y_test, batch_size=64, verbose=0)
print(f"Student Model Test Accuracy: {sm_gru_test_accuracy * 100}")

gru_accuracy_diff = tm_gru_test_accuracy - sm_gru_test_accuracy
print(f"Accuracy Difference (Teacher - Student): {gru_accuracy_diff * 100}%")

"""<h2><b> Plotting the Result </b></h2>"""

model_history = [lstm_256_teacher_history, lstm_128_teacher_history, gru_history]

for i in range(len(model_history)):

    history = model_history[i]

    # Create a list of epoch numbers based on the length of the accuracy arrays
    epochs = list(range(len(history.history['accuracy'])))

    # Extract training accuracy and validation accuracy from the history object
    acc = history.history['accuracy']           # Training accuracy
    val_acc = history.history['val_accuracy']   # Validation accuracy

    # Plot training and validation accuracy
    plt.plot(epochs, acc, label='train accuracy')
    plt.plot(epochs, val_acc, label='val accuracy')

    # Set the labels for the x and y axes
    plt.xlabel('epochs')
    plt.ylabel('accuracy')

    # Set the title of the plot
    plt.title(f"{model_history[i]}")
    # Show legend and plot
    plt.legend()
    plt.show()

for i in range(len(model_history)):

    history = model_history[i]

    epochs = list(range(len(history.history['accuracy'])))

    # Extract the loss and validation loss from the history object
    loss = history.history['loss']          # Training Loss
    val_loss = history.history['val_loss']  # Validation Loss

    plt.plot(epochs, loss, label='train loss')   # Plot training loss
    plt.plot(epochs, val_loss, label='val loss') # Plot validation loss

    # Set the labels for the x and y axes
    plt.xlabel('epochs')
    plt.ylabel('loss')

    # Set the title of the plot
    plt.title(f"{model_history[i]}")
    plt.legend() # Legend to differentiate between training and validation accuracy
    plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

"""<h2><b>Prediction</b></h2>"""

models = [lstm_256_teacher_model, lstm_128_teacher_model, gru_model]
for i in range(len(models)):

    model = models[i]

    # Generate predictions for the test dataset using the teacher model
    y_pred = model.predict(X_test)

    # Convert predicted probabilities to class labels by taking the index of the maximum probability
    y_pred_classes = np.argmax(y_pred, axis=1)

    # Convert one-hot encoded true labels to class labels by taking the index of the maximum value in each row
    y_test_classes = np.argmax(y_test, axis=1)

    print(f"{model}")
    # Print the first 100 predicted and actual labels for comparison
    # print(f"Predicted labels: {y_pred_classes[:100]}")
    # print(f"Actual labels: {y_test_classes[:100]}")


    # Compute the confusion matrix using the true labels and predicted labels
    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)

    # Get the class labels from the OneHotEncoder used during training
    labels = enc.categories_[0]

    # Set up the figure for the confusion matrix
    plt.figure(figsize=(10, 7))

    # Create a heatmap to visualize the confusion matrix
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)

    # Set the labels for the x and y axes
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix') # Set the title of the plot
    plt.show()

!mkdir Predict

# Initialize an empty dictionary to store label and corresponding one-hot encoding
label_to_onehot = {}

# Get the unique labels from the encoder
unique_labels = enc.categories_[0]

# Loop to store the label and its corresponding one-hot encoding in the dictionary
for i, label in enumerate(unique_labels):
    encoding = [0] * len(unique_labels)  # Initialize a zero array
    encoding[i] = 1  # Set 1 at the position corresponding to the current label
    label_to_onehot[label] = encoding  # Store in the dictionary

# Now you have a dictionary with labels as keys and one-hot encodings as values
label_to_onehot

import librosa
import numpy as np
from keras.models import load_model

# List of emotions corresponding to the output classes in your model
emotions = ['fear', 'ps', 'sad', 'angry', 'disgust', 'happy', 'neutral']

# Function to extract MFCCs from an audio file
def extract_mfcc(filename):
    # Load the audio file with librosa
    # 'duration' specifies the length of the audio clip to load (in seconds)
    # 'offset' specifies the start time to load the audio
    y, sr = librosa.load(filename, duration=3, offset=0.5)

    # Extract MFCC features from the audio data
    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=60).T, axis=0)
    return mfcc

# audio_file = '/content/TESS Toronto emotional speech set data/YAF_angry/YAF_back_angry.wav'
# audio_mfcc = extract_mfcc(audio_file)
# # audio_mfcc

# audio_mfcc = np.expand_dims(audio_mfcc, axis=0)  # Add batch dimension
# # audio_mfcc

# audio_mfcc = np.expand_dims(audio_mfcc, axis=-1)  # Add channel dimension
# # audio_mfcc

# audio_pred = teacher_model.predict(audio_mfcc)
# audio_pred_classes = np.argmax(audio_pred, axis=1)
# print(f"Predicted labels: {audio_pred_classes}")

# for label in label_to_onehot:
#     if label_to_onehot[label][audio_pred_classes[0]] == 1:
#         print(f"Predicted emotion: {label}")

predict_dir = r'/content/Predict'
predict_paths = []

for dirname, _, filenames in os.walk(predict_dir):
    for filename in filenames:
        predict_paths.append(os.path.join(dirname, filename))
predict_paths

# Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).
for audio_file in predict_paths:
    audio_mfcc = extract_mfcc(audio_file)
    audio_mfcc = np.expand_dims(audio_mfcc, axis=0)  # Add batch dimension
    audio_mfcc = np.expand_dims(audio_mfcc, axis=-1)  # Add channel dimension

    audio_pred = lstm_256_teacher_model.predict(audio_mfcc)[0]
    # audio_pred_classes = np.argmax(audio_pred, axis=1)
    # print(f"Predicted labels: {audio_pred_classes}")

    n = 3
    top_n_indices = np.argsort(audio_pred)[-n:][::-1]

    for label in label_to_onehot:
        for i in range(n):
            if label_to_onehot[label][top_n_indices[i]] == 1:
                print(f"Predicted emotion: {label}")

"""<h3> <b> Transformer Model Prediction</b> <h3>"""

predict_folder = r'/content/Predict'

# Function to load and preprocess an audio file
def preprocess_audio(file_path, processor, max_length=32000):
    # Load the audio file
    speech, sr = librosa.load(file_path, sr=16000)

    # Pad or truncate the speech to the required length
    if len(speech) > max_length:
        speech = speech[:max_length]
    else:
        speech = np.pad(speech, (0, max_length - len(speech)), 'constant')

    # Preprocess the audio
    inputs = processor(
        speech, sampling_rate=16000, return_tensors='pt', padding=True, truncation=True, max_length=max_length
    )
    return inputs.input_values.squeeze()

# Function to predict the top three labels of audio files in a folder
def predict_top_three_labels(folder_path, model, processor, label_map):
    # Get all audio files in the folder
    audio_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]

    if not audio_files:
        print("No audio files found in the folder!")
        return

    predictions = []

    for audio_file in audio_files:
        file_path = os.path.join(folder_path, audio_file)
        try:
            # Preprocess the audio
            input_values = preprocess_audio(file_path, processor).unsqueeze(0).cuda()

            # Perform inference
            with torch.no_grad():
                outputs = model(input_values)
                logits = outputs.logits
                probabilities = torch.nn.functional.softmax(logits, dim=-1).squeeze()

            # Get the top 3 predicted classes and their probabilities
            top3_indices = torch.topk(probabilities, k=3).indices.tolist()
            top3_probs = torch.topk(probabilities, k=3).values.tolist()
            top3_labels = [inverse_label_map[idx] for idx in top3_indices]

            # Combine results
            top3_predictions = list(zip(top3_labels, top3_probs))
            predictions.append((audio_file, top3_predictions))
        except Exception as e:
            print(f"Error processing file {audio_file}: {e}")

    return predictions

# Predict top-3 labels for audio files in the Predict folder
predictions = predict_top_three_labels(predict_folder, tf_model, processor, inverse_label_map)

# Display predictions
if predictions:
    print("Predictions:")
    for audio_file, top3 in predictions:
        print(f"{audio_file}:")
        for label, prob in top3:
            print(f"    {label}: {prob:.4f}")
        print()

import os
import shutil

# Specify the folder path
folder_path = '/content/Predict'

# Remove all files from the folder
for filename in os.listdir(folder_path):
    file_path = os.path.join(folder_path, filename)
    try:
        if os.path.isfile(file_path) or os.path.islink(file_path):
            os.unlink(file_path)  # Remove file or symlink
        elif os.path.isdir(file_path):
            shutil.rmtree(file_path)  # Remove directory and its contents
    except Exception as e:
        print(f'Failed to delete {file_path}. Reason: {e}')

